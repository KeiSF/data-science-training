{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PACKAGES\n",
    "import os\n",
    "os.chdir('./4.Santander_Customer_Satisfaction')\n",
    "import sys\n",
    "sys.path.insert(0, '../mylib/')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from show_data import print_full\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from operator import itemgetter\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import robust_scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MAGIC COMMANDS\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LOAD DATA FILES\n",
    "training_df = pd.read_csv('train.csv')\n",
    "scoring_df = pd.read_csv('test.csv')\n",
    "sample_submission_df = pd.read_csv('sample_submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "# EXPLORATORY ANALYSIS\n",
    "#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get statistics about the features\n",
    "desc = training_df.describe()\n",
    "#desc.to_csv('describe.csv')\n",
    "desc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get name and type of features\n",
    "#for x in training_df.columns:\n",
    "# print (x, training_df[x].dtype)\n",
    "print ('number of features: ', len(training_df.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Deal with missing values: not missing values\n",
    "for x in training_df.columns:\n",
    "    if training_df[x].isnull().any():\n",
    "        print x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check if there is any repeated ID, which would imply to tidy the data set:\n",
    "id_counts_df = training_df['ID'].value_counts().sort_index() # count the number of occurrences of each ID\n",
    "max(id_counts_df) # if the max value is 1, then there are no repeated IDs = 1 row for each observation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Percentage of target == 1: ~ 4% --> very unbalanced!\n",
    "float(len(training_df[training_df['TARGET']==1]))/len(training_df['TARGET']) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "# PREPROCESSING\n",
    "#######################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove IDs\n",
    "training_df.drop(['ID'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove constant features\n",
    "# \"Constant features can lead to errors in some models and obviously provide no information in the training set that can be learned from.\"\n",
    "remove = []\n",
    "count_constants = 0\n",
    "for col in training_df.columns:\n",
    "    if training_df[col].values.std() == 0: # pandas.series std() is not correct, use numpy std() instead (.values.std() instead of std())\n",
    "        #print col\n",
    "        remove.append(col)\n",
    "        count_constants += 1\n",
    "training_df.drop(remove, axis=1, inplace=True)\n",
    "#test_df.drop(remove, axis=1, inplace=True)\n",
    "print ('number of constant features removed: ', count_constants)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove duplicated columns\n",
    "remove = []\n",
    "c = training_df.columns\n",
    "count_duplicated = 0\n",
    "for i in range(len(c)-1):\n",
    "    v = training_df[c[i]].values\n",
    "    for j in range(i+1,len(c)):\n",
    "        if np.array_equal(v,training_df[c[j]].values):\n",
    "            #print c[j]\n",
    "            remove.append(c[j])\n",
    "            count_duplicated += 1\n",
    "\n",
    "training_df.drop(remove, axis=1, inplace=True)\n",
    "#test_df.drop(remove, axis=1, inplace=True)\n",
    "print ('number of duplicated features removed: ', count_duplicated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positives = training_df[training_df['TARGET']==1]\n",
    "negatives = training_df[training_df['TARGET']==0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BALANCE THE DATASET: 3008 with TARGET==1, 3008 with TARGET==0\n",
    "training_positive = positives[0:1504]#.reset_index(drop=True)\n",
    "training_negative = negatives[0:1504]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_df = pd.concat([training_positive, training_negative])\n",
    "training_df = training_df.reindex(np.random.permutation(training_df.index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_positive = positives[1504:3008]\n",
    "test_negative = negatives[1504:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.concat([test_positive, test_negative])\n",
    "test_df = test_df.reindex(np.random.permutation(test_df.index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################\n",
    "# FEATURE SELECTION\n",
    "####################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove features with low variance:\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "def VarianceThreshold_selector(data, th):\n",
    "    #Select Model\n",
    "    selector = VarianceThreshold(th) #Defaults to 0.0, e.g. only remove features with the same value in all samples\n",
    "    #Fit the Model\n",
    "    selector.fit(data)\n",
    "    features = selector.get_support(indices = True) #returns an array of integers corresponding to nonremoved features\n",
    "    features = [column for column in data[features]] #Array of all nonremoved features' names\n",
    "    #Format and Return\n",
    "    selector = pd.DataFrame(selector.transform(data))\n",
    "    selector.columns = features\n",
    "    return selector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# keep the ID by index\n",
    "#index_id = training_df['ID']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_df_vth = pd.concat([VarianceThreshold_selector(training_df.iloc[:,:-1], 0.9), training_df.iloc[:,-1]], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_df_vth.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Univariate feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split between features and target variable\n",
    "X, y = training_df_vth.iloc[:,:-1], training_df_vth.iloc[:, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove features which are not correlated to the target variable by using recursive feature elimination (by checking subsets)\n",
    "# with cross-validation. Wrapped method with logistic Regression (with C=1, low regularization strengh)\n",
    "#from sklearn.feature_selection import RFECV\n",
    "#from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# My computer takes ages to compute this\n",
    "#estimator = LogisticRegression()\n",
    "#selector = RFECV(estimator, step=1, cv=3, n_jobs=4)\n",
    "#selector = selector.fit(X, y)\n",
    "#selector.support_\n",
    "#selector.ranking_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove features which are not correlated to the target variable by using univariate feature selection, keep the top 5%\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import f_classif\n",
    "selector = SelectPercentile(score_func = f_classif, percentile = 35)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_reduced = selector.fit_transform(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_reduced.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "# EXPLORATORY ANALYSIS 2\n",
    "#########################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Chosen features:\n",
    "keep = X.iloc[:,selector.get_support()].columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X.iloc[:,selector.get_support()].hist(color='k', alpha=0.5, bins=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################################################################################\n",
    "##########################################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################\n",
    "# SIMPLEST MODEL:\n",
    "#################\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# FEATURES: X.iloc[:,selector.get_support()],\n",
    "# TARGET: y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SIMPLE TRAINING\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X.iloc[:,selector.get_support()], y, test_size=0.20)\n",
    "X_train = X.iloc[:,selector.get_support()]\n",
    "#clf = LogisticRegression(C=1)\n",
    "#clf = GaussianNB()\n",
    "#clf = SVC()\n",
    "#clf = DecisionTreeClassifier()\n",
    "#clf = RandomForestClassifier()\n",
    "#clf = AdaBoostClassifier(LogisticRegression(C=1), n_estimators=100)\n",
    "clf = GradientBoostingClassifier()\n",
    "#clf = AdaBoostClassifier(n_estimators=100)\n",
    "#clf.fit(X_train, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.get_params().keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'max_depth':[1, 2, 3, 4, 5]}\n",
    "est = GradientBoostingClassifier()\n",
    "clf = GridSearchCV(est, parameters)\n",
    "clf.fit(X_train, y)\n",
    "sorted(clf.cv_results_.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SIMPLE TESTING\n",
    "\n",
    "roc_auc_score(test_df['TARGET'], clf.predict(test_df[keep]))\n",
    "\n",
    "# Logistic Regression:\n",
    "# 0.7091457517325841 con 18% de relevant features (25)\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "# 0.69264412016390964 con 18% de relevant features (25)\n",
    "\n",
    "# Support Vector Classifier\n",
    "# 0.71902264097217505 con 5% de relevant features (8)\n",
    "\n",
    "# Decision Tree\n",
    "# 0.67486172131908473 (0.97539893617021267 en training set) con 18% de relevant features (25).\n",
    "# Parece tener overfitting (mucha varianza),\n",
    "# podría reducirse utilizando un método de averagging entre varios árboles - > RandomForest\n",
    "# -> no lo soluciona, probemos con menos features -> Ahora si\n",
    "# Con 8% de relevant features (12) mejora bastante, ya no tiene tanto overfitting\n",
    "\n",
    "# Random Forest\n",
    "# 0.73459806312401899 con 8% de relevant features (12)\n",
    "# Probemos Boosting con un modelo que tenga high bias (Logistic Regression con pocas features): no mejora nada, no reduce bias\n",
    "# ~ Logistic Regression\n",
    "\n",
    "# AdaBoost con Trees\n",
    "# 0.75120072861956222 con 18% de relevant features (25)\n",
    "\n",
    "# Gradient Boosting\n",
    "# 0.7572604396889383 con 18% de relevant features (25)\n",
    "# 0.7610946893012418 con el 35% de relevant features (51)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "roc_auc_score(y, clf.predict(X_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross-validation TEST with auc score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(clf, X_train, y, cv=5, scoring='roc_auc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sample_submission_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scoring_y = clf.predict(scoring_df[keep])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.concat([scoring_df['ID'], pd.DataFrame(scoring_y, index=scoring_df.index)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = result.rename(columns={0: \"TARGET\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result.to_csv('leaderboard_submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################\n",
    "# LEARNING CURVES\n",
    "#################\n",
    "\n",
    "rg = range(100, 10000, 10)\n",
    "training_scores = np.zeros((2, len(rg)))\n",
    "test_scores = np.zeros((2, len(rg)))\n",
    "nrows, ncols = X_train.shape\n",
    "clf = LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "for j in rg:\n",
    "    \n",
    "    clf.fit(X_train.iloc[1:j,:], y_train[1:j])\n",
    "\n",
    "    # TRAINING score\n",
    "    training_scores[0, counter] = roc_auc_score(y_train, clf.predict(X_train))\n",
    "    training_scores[1, counter] = j\n",
    "\n",
    "    # TESTING score\n",
    "    test_scores[0, counter] = roc_auc_score(y_test, clf.predict(X_test))\n",
    "    test_scores[1, counter] = j\n",
    "    counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PLOT THESE LEARNING CURVES:\n",
    "#plt.plot(training_scores[1,:], training_scores[0,:],'r', test_scores[1,:], test_scores[0,:],"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
